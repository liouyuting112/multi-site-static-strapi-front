import requests
import json
import sys
import os
import re
import ssl
from pathlib import Path
from urllib3.util.ssl_ import create_urllib3_context

# ç¦ç”¨ SSL è­¦å‘Šå’Œé©—è­‰
import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# å‰µå»ºè‡ªå®šç¾©çš„ SSL é©é…å™¨ï¼ˆæœ€å¾¹åº•çš„ SSL è¨­å®šï¼‰
class SSLAdapter(requests.adapters.HTTPAdapter):
    def init_poolmanager(self, *args, **kwargs):
        # å‰µå»ºæœ€å¯¬é¬†çš„ SSL ä¸Šä¸‹æ–‡
        ctx = ssl._create_unverified_context()
        ctx.check_hostname = False
        ctx.verify_mode = ssl.CERT_NONE
        # è¨­å®šè¼ƒä½çš„å®‰å…¨ç´šåˆ¥å’Œè¼ƒèˆŠçš„å”è­°
        try:
            ctx.set_ciphers('DEFAULT:@SECLEVEL=1')
            # å…è¨±è¼ƒèˆŠçš„ TLS ç‰ˆæœ¬
            ctx.minimum_version = ssl.TLSVersion.MINIMUM_SUPPORTED
            ctx.maximum_version = ssl.TLSVersion.MAXIMUM_SUPPORTED
        except:
            pass
        kwargs['ssl_context'] = ctx
        return super().init_poolmanager(*args, **kwargs)

# å‰µå»º session ä¸¦è¨­å®š SSL é©é…å™¨
session = requests.Session()
session.mount('https://', SSLAdapter())

# é¡å¤–è¨­å®šï¼šå¼·åˆ¶ urllib3 ä½¿ç”¨ä¸é©—è­‰çš„ SSL
try:
    import urllib3.poolmanager
    orig_init = urllib3.poolmanager.PoolManager.__init__
    def new_init(self, *args, **kwargs):
        if 'ssl_context' not in kwargs:
            ctx = ssl._create_unverified_context()
            ctx.check_hostname = False
            ctx.verify_mode = ssl.CERT_NONE
            kwargs['ssl_context'] = ctx
        return orig_init(self, *args, **kwargs)
    urllib3.poolmanager.PoolManager.__init__ = new_init
except:
    pass

# =========================================================
# ğŸ¯ è¨­ç½®å€å¡Šï¼šè«‹æª¢æŸ¥ä¸¦ä¿®æ”¹ä»¥ä¸‹è®Šæ•¸
# =========================================================

# 1. Strapi ä¼ºæœå™¨åŸºç¤ URLï¼ˆé›²ç«¯ Strapiï¼‰
STRAPI_BASE_URL = os.getenv('STRAPI_URL', 'https://tidy-fireworks-ad201d981a.strapiapp.com')

# 2. æ‚¨çš„ Full Access API æ¬Šæ–ï¼ˆå¾ç’°å¢ƒè®Šæ•¸è®€å–ï¼‰
API_TOKEN = os.getenv('STRAPI_TOKEN', '')

if not API_TOKEN:
    print('âŒ éŒ¯èª¤ï¼šè«‹è¨­å®š STRAPI_TOKEN ç’°å¢ƒè®Šæ•¸')
    print('\nè«‹åŸ·è¡Œï¼š')
    print('  $env:STRAPI_URL="https://tidy-fireworks-ad201d981a.strapiapp.com"')
    print('  $env:STRAPI_TOKEN="ä½ çš„API_TOKEN"')
    print('  python import-strapi-cloud.py')
    sys.exit(1)

# 3. API ç«¯é»
POSTS_ENDPOINT = "/api/posts"
PAGES_ENDPOINT = "/api/pages"

# =========================================================
# ğŸ› ï¸ å·¥å…·å‡½æ•¸
# =========================================================

def extract_title(html_content):
    """å¾ HTML æå–æ¨™é¡Œ"""
    match = re.search(r'<title>([^<]+)</title>', html_content, re.IGNORECASE)
    if match:
        title = match.group(1).strip()
        # ç§»é™¤ç¶²ç«™åç¨±ï¼ˆä¾‹å¦‚ " | åƒç´ æ™‚å…‰"ï¼‰
        title = re.sub(r'\s*\|\s*.*$', '', title)
        return title
    return 'Untitled'

def extract_article_content(html_content):
    """å¾ HTML æå–æ–‡ç« å…§å®¹ï¼ˆ<article class="article-content">ï¼‰"""
    # å„ªå…ˆæå– <article class="article-content">
    match = re.search(r'<article[^>]*class="article-content"[^>]*>([\s\S]*?)</article>', html_content, re.IGNORECASE)
    if match:
        content = match.group(1).strip()
        # ç§»é™¤ <h1> æ¨™é¡Œ
        content = re.sub(r'<h1[^>]*>[\s\S]*?</h1>', '', content, flags=re.IGNORECASE)
        return content
    
    # é€€è€Œæ±‚å…¶æ¬¡ï¼šæå–ä»»æ„ <article>
    match = re.search(r'<article[^>]*>([\s\S]*?)</article>', html_content, re.IGNORECASE)
    if match:
        content = match.group(1).strip()
        content = re.sub(r'<h1[^>]*>[\s\S]*?</h1>', '', content, flags=re.IGNORECASE)
        return content
    
    return None

def extract_page_content(html_content):
    """å¾ HTML æå–é é¢å…§å®¹ï¼ˆ<main> æˆ– <body>ï¼‰"""
    # å„ªå…ˆæå– <main> å…§å®¹
    match = re.search(r'<main[^>]*>([\s\S]*?)</main>', html_content, re.IGNORECASE)
    if match:
        return match.group(1).strip()
    
    # é€€è€Œæ±‚å…¶æ¬¡ï¼šæå– <body> å…§å®¹
    match = re.search(r'<body[^>]*>([\s\S]*?)</body>', html_content, re.IGNORECASE)
    if match:
        return match.group(1).strip()
    
    return html_content

def extract_date_from_filename(filename):
    """å¾æª”åæå–æ—¥æœŸï¼ˆä¾‹å¦‚ï¼š2025-12-03.html -> 2025-12-03ï¼‰"""
    match = re.search(r'(\d{4}-\d{2}-\d{2})', filename)
    return match.group(1) if match else None

def extract_image_url(html_content):
    """å¾ HTML æå–åœ–ç‰‡ URL"""
    match = re.search(r'<img[^>]*src=["\']([^"\']+)["\']', html_content, re.IGNORECASE)
    return match.group(1) if match else None

# =========================================================
# ğŸš€ API å‡½æ•¸
# =========================================================

def create_strapi_post(data):
    """å‘ Strapi ä¼ºæœå™¨ç™¼é€ POST è«‹æ±‚ä»¥å‰µå»ºæ–‡ç« """
    url = f"{STRAPI_BASE_URL}{POSTS_ENDPOINT}"
    
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {API_TOKEN}"
    }
    
    payload = {"data": data}
    
    try:
        response = session.post(
            url,
            headers=headers,
            data=json.dumps(payload),
            verify=False,
            timeout=30
        )
        
        if response.status_code in [200, 201]:
            return response.json()
        else:
            print(f"âŒ å‰µå»ºå¤±æ•—ï¼Œç‹€æ…‹ç¢¼: {response.status_code}")
            print(f"   éŒ¯èª¤: {response.text[:200]}")
            return None
    except Exception as e:
        print(f"âŒ è«‹æ±‚éŒ¯èª¤: {str(e)}")
        return None

def update_strapi_post(post_id, data):
    """æ›´æ–° Strapi æ–‡ç« """
    url = f"{STRAPI_BASE_URL}{POSTS_ENDPOINT}/{post_id}"
    
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {API_TOKEN}"
    }
    
    payload = {"data": data}
    
    try:
        response = session.put(
            url,
            headers=headers,
            data=json.dumps(payload),
            verify=False,
            timeout=30
        )
        
        if response.status_code == 200:
            return response.json()
        else:
            print(f"âŒ æ›´æ–°å¤±æ•—ï¼Œç‹€æ…‹ç¢¼: {response.status_code}")
            return None
    except Exception as e:
        print(f"âŒ è«‹æ±‚éŒ¯èª¤: {str(e)}")
        return None

def find_post_by_slug(site, slug):
    """æ ¹æ“š site å’Œ slug æŸ¥æ‰¾æ–‡ç« """
    url = f"{STRAPI_BASE_URL}{POSTS_ENDPOINT}?filters[site][$eq]={site}&filters[slug][$eq]={slug}"
    
    headers = {
        "Authorization": f"Bearer {API_TOKEN}"
    }
    
    try:
        response = session.get(url, headers=headers, verify=False, timeout=30)
        if response.status_code == 200:
            data = response.json()
            posts = data.get('data', [])
            return posts[0] if posts else None
        return None
    except Exception as e:
        print(f"âŒ æŸ¥è©¢éŒ¯èª¤: {str(e)}")
        return None

def create_strapi_page(data):
    """å‰µå»º Strapi é é¢"""
    url = f"{STRAPI_BASE_URL}{PAGES_ENDPOINT}"
    
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {API_TOKEN}"
    }
    
    payload = {"data": data}
    
    try:
        response = session.post(
            url,
            headers=headers,
            data=json.dumps(payload),
            verify=False,
            timeout=30
        )
        
        if response.status_code in [200, 201]:
            return response.json()
        else:
            print(f"âŒ å‰µå»ºå¤±æ•—ï¼Œç‹€æ…‹ç¢¼: {response.status_code}")
            return None
    except Exception as e:
        print(f"âŒ è«‹æ±‚éŒ¯èª¤: {str(e)}")
        return None

def update_strapi_page(page_id, data):
    """æ›´æ–° Strapi é é¢"""
    url = f"{STRAPI_BASE_URL}{PAGES_ENDPOINT}/{page_id}"
    
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {API_TOKEN}"
    }
    
    payload = {"data": data}
    
    try:
        response = session.put(
            url,
            headers=headers,
            data=json.dumps(payload),
            verify=False,
            timeout=30
        )
        
        if response.status_code == 200:
            return response.json()
        else:
            print(f"âŒ æ›´æ–°å¤±æ•—ï¼Œç‹€æ…‹ç¢¼: {response.status_code}")
            return None
    except Exception as e:
        print(f"âŒ è«‹æ±‚éŒ¯èª¤: {str(e)}")
        return None

def find_page_by_type(site, page_type):
    """æ ¹æ“š site å’Œ type æŸ¥æ‰¾é é¢"""
    url = f"{STRAPI_BASE_URL}{PAGES_ENDPOINT}?filters[site][$eq]={site}&filters[type][$eq]={page_type}"
    
    headers = {
        "Authorization": f"Bearer {API_TOKEN}"
    }
    
    try:
        response = session.get(url, headers=headers, verify=False, timeout=30)
        if response.status_code == 200:
            data = response.json()
            pages = data.get('data', [])
            return pages[0] if pages else None
        return None
    except Exception as e:
        print(f"âŒ æŸ¥è©¢éŒ¯èª¤: {str(e)}")
        return None

# =========================================================
# ğŸ“„ åŒ¯å…¥é é¢
# =========================================================

def import_pages():
    """åŒ¯å…¥æ‰€æœ‰ç«™é»çš„é é¢"""
    print('ğŸ“„ é–‹å§‹åŒ¯å…¥é é¢...\n')
    
    base_dir = Path(__file__).parent.parent
    page_defs = [
        {'type': 'home', 'file': 'index.html', 'slug': 'index'},
        {'type': 'contact', 'file': 'contact.html', 'slug': 'contact'},
        {'type': 'about', 'file': 'about.html', 'slug': 'about'},
        {'type': 'privacy', 'file': 'privacy.html', 'slug': 'privacy'}
    ]
    
    success_count = 0
    fail_count = 0
    
    for site_num in range(1, 6):
        site = f'site{site_num}'
        site_dir = base_dir / site
        
        if not site_dir.exists():
            print(f'âš ï¸  æ‰¾ä¸åˆ°ç›®éŒ„ï¼š{site}ï¼Œè·³é')
            continue
        
        print(f'\nè™•ç† {site}...')
        
        for page_def in page_defs:
            file_path = site_dir / page_def['file']
            if not file_path.exists():
                print(f'  â­ï¸  è·³éï¼š{page_def["file"]}ï¼ˆæª”æ¡ˆä¸å­˜åœ¨ï¼‰')
                continue
            
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    html_content = f.read()
                
                title = extract_title(html_content)
                content = extract_page_content(html_content)
                
                # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨
                existing = find_page_by_type(site, page_def['type'])
                
                page_data = {
                    'site': site,
                    'type': page_def['type'],
                    'slug': page_def['slug'],
                    'title': title,
                    'html': content
                }
                
                if existing:
                    # æ›´æ–°
                    page_id = existing.get('id')
                    result = update_strapi_page(page_id, page_data)
                    if result:
                        print(f'  âœ… æ›´æ–°ï¼š{page_def["type"]}')
                        success_count += 1
                    else:
                        print(f'  âŒ æ›´æ–°å¤±æ•—ï¼š{page_def["type"]}')
                        fail_count += 1
                else:
                    # å»ºç«‹
                    result = create_strapi_page(page_data)
                    if result:
                        print(f'  âœ… å»ºç«‹ï¼š{page_def["type"]}')
                        success_count += 1
                    else:
                        print(f'  âŒ å»ºç«‹å¤±æ•—ï¼š{page_def["type"]}')
                        fail_count += 1
                        
            except Exception as e:
                print(f'  âŒ éŒ¯èª¤ï¼š{page_def["type"]} - {str(e)}')
                fail_count += 1
    
    print(f'\nğŸ“Š é é¢åŒ¯å…¥å®Œæˆï¼šæˆåŠŸ {success_count}ï¼Œå¤±æ•— {fail_count}')
    return success_count, fail_count

# =========================================================
# ğŸ“ åŒ¯å…¥æ–‡ç« 
# =========================================================

def import_article(site, slug, file_path, category='daily'):
    """åŒ¯å…¥å–®ç¯‡æ–‡ç« """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            html_content = f.read()
        
        title = extract_title(html_content)
        content = extract_article_content(html_content)
        date = extract_date_from_filename(file_path.name)
        image_url = extract_image_url(html_content)
        
        if not content:
            print(f'  âš ï¸  ç„¡æ³•æå–å…§å®¹ï¼š{slug}')
            return False
        
        # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨
        existing = find_post_by_slug(site, slug)
        
        post_data = {
            'site': site,
            'category': category,
            'slug': slug,
            'title': title,
            'html': content,
            'date': date,
            'isFeatured': True if category == 'daily' else False
        }
        
        if image_url:
            post_data['imageUrl'] = image_url
        
        if existing:
            # æ›´æ–°
            post_id = existing.get('id')
            result = update_strapi_post(post_id, post_data)
            if result:
                print(f'  âœ… æ›´æ–°ï¼š{slug}')
                return True
            else:
                print(f'  âŒ æ›´æ–°å¤±æ•—ï¼š{slug}')
                return False
        else:
            # å»ºç«‹
            result = create_strapi_post(post_data)
            if result:
                print(f'  âœ… å»ºç«‹ï¼š{slug}')
                return True
            else:
                print(f'  âŒ å»ºç«‹å¤±æ•—ï¼š{slug}')
                return False
                
    except Exception as e:
        print(f'  âŒ éŒ¯èª¤ï¼š{slug} - {str(e)}')
        return False

# =========================================================
# ğŸš€ ä¸»ç¨‹åº
# =========================================================

def main():
    print('ğŸš€ é–‹å§‹åŒ¯å…¥å…§å®¹åˆ°é›²ç«¯ Strapi...')
    print(f'ğŸ“ Strapi URL: {STRAPI_BASE_URL}\n')
    
    # æ¸¬è©¦é€£æ¥
    try:
        print('ğŸ” æ¸¬è©¦é€£æ¥åˆ° Strapi...')
        response = session.get(
            f'{STRAPI_BASE_URL}/api',
            headers={'Authorization': f'Bearer {API_TOKEN}'},
            verify=False,
            timeout=30
        )
        if response.status_code == 200:
            print('âœ… é€£æ¥æˆåŠŸï¼\n')
        else:
            print(f'âŒ é€£æ¥å¤±æ•—: {response.status_code}')
            return
    except Exception as e:
        print(f'âŒ é€£æ¥éŒ¯èª¤: {str(e)}')
        return
    
    # åŒ¯å…¥é é¢
    import_pages()
    
    print('\nâœ… é é¢åŒ¯å…¥å®Œæˆï¼')
    print('\nâš ï¸  æ³¨æ„ï¼š')
    print('   1. å›ºå®šæ–‡ç« å’Œæ¯æ—¥æ–‡ç« éœ€è¦æ‰‹å‹•åŒ¯å…¥')
    print('   2. ä½¿ç”¨æ–¹å¼ï¼š')
    print('      import_article("site1", "2025-12-03", Path("site1/articles/2025-12-03.html"), "daily")')
    print('      import_article("site1", "retro-vs-modern", Path("site1/articles/retro-vs-modern.html"), "fixed")')

if __name__ == "__main__":
    main()

