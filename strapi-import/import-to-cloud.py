#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŒ¯å…¥å…§å®¹åˆ°é›²ç«¯ Strapi
ä½¿ç”¨æ–¹å¼ï¼š
    python import-to-cloud.py
"""

import os
import json
import requests
import re
from pathlib import Path

# è¨­å®šï¼ˆå¾ç’°å¢ƒè®Šæ•¸è®€å–ï¼‰
STRAPI_URL = os.getenv('STRAPI_URL', 'https://tidy-fireworks-ad201d981a.strapiapp.com')
STRAPI_TOKEN = os.getenv('STRAPI_TOKEN', '')

if not STRAPI_TOKEN:
    print('âŒ éŒ¯èª¤ï¼šè«‹è¨­å®š STRAPI_TOKEN ç’°å¢ƒè®Šæ•¸')
    print('\nè«‹åŸ·è¡Œï¼š')
    print('  $env:STRAPI_URL="https://tidy-fireworks-ad201d981a.strapiapp.com"')
    print('  $env:STRAPI_TOKEN="ä½ çš„API_TOKEN"')
    print('  python import-to-cloud.py')
    exit(1)

# è¨­å®š headers
headers = {
    'Content-Type': 'application/json',
    'Authorization': f'Bearer {STRAPI_TOKEN}'
}

# ç¦ç”¨ SSL é©—è­‰ï¼ˆåƒ…ç”¨æ–¼é–‹ç™¼/æ¸¬è©¦ï¼‰
requests.packages.urllib3.disable_warnings()

def extract_title(html_content):
    """å¾ HTML æå–æ¨™é¡Œ"""
    match = re.search(r'<title>([^<]+)</title>', html_content, re.IGNORECASE)
    if match:
        title = match.group(1).strip()
        # ç§»é™¤ç¶²ç«™åç¨±
        title = re.sub(r'\s*\|\s*.*$', '', title)
        return title
    return 'Untitled'

def extract_content(html_content):
    """å¾ HTML æå–å…§å®¹"""
    # å„ªå…ˆæå– <main> å…§å®¹
    match = re.search(r'<main[^>]*>([\s\S]*?)</main>', html_content, re.IGNORECASE)
    if match:
        return match.group(1).strip()
    
    # é€€è€Œæ±‚å…¶æ¬¡ï¼šæå– <body> å…§å®¹
    match = re.search(r'<body[^>]*>([\s\S]*?)</body>', html_content, re.IGNORECASE)
    if match:
        return match.group(1).strip()
    
    return html_content

def import_page(site, page_type, file_path):
    """åŒ¯å…¥å–®å€‹é é¢"""
    try:
        # è®€å– HTML æª”æ¡ˆ
        with open(file_path, 'r', encoding='utf-8') as f:
            html_content = f.read()
        
        title = extract_title(html_content)
        content = extract_content(html_content)
        
        # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨
        check_url = f'{STRAPI_URL}/api/pages?filters[site][$eq]={site}&filters[type][$eq]={page_type}'
        response = requests.get(check_url, headers=headers, verify=False, timeout=30)
        
        if response.status_code == 200:
            data = response.json()
            existing = data.get('data', [])
            
            payload = {
                'data': {
                    'site': site,
                    'type': page_type,
                    'slug': page_type if page_type != 'home' else 'index',
                    'title': title,
                    'html': content
                }
            }
            
            if existing and len(existing) > 0:
                # æ›´æ–°
                page_id = existing[0].get('id')
                update_url = f'{STRAPI_URL}/api/pages/{page_id}'
                response = requests.put(update_url, headers=headers, json=payload, verify=False, timeout=30)
                if response.status_code == 200:
                    print(f'  âœ… æ›´æ–°ï¼š{page_type}')
                    return True
                else:
                    print(f'  âŒ æ›´æ–°å¤±æ•—ï¼š{page_type} ({response.status_code})')
                    return False
            else:
                # å»ºç«‹
                create_url = f'{STRAPI_URL}/api/pages'
                response = requests.post(create_url, headers=headers, json=payload, verify=False, timeout=30)
                if response.status_code == 200:
                    print(f'  âœ… å»ºç«‹ï¼š{page_type}')
                    return True
                else:
                    print(f'  âŒ å»ºç«‹å¤±æ•—ï¼š{page_type} ({response.status_code})')
                    print(f'     éŒ¯èª¤ï¼š{response.text[:200]}')
                    return False
        else:
            print(f'  âŒ æŸ¥è©¢å¤±æ•—ï¼š{page_type} ({response.status_code})')
            return False
            
    except Exception as e:
        print(f'  âŒ éŒ¯èª¤ï¼š{page_type} - {str(e)}')
        return False

def main():
    print('ğŸš€ é–‹å§‹åŒ¯å…¥å…§å®¹åˆ°é›²ç«¯ Strapi...')
    print(f'ğŸ“ Strapi URL: {STRAPI_URL}\n')
    
    # æ¸¬è©¦é€£æ¥
    try:
        print('ğŸ” æ¸¬è©¦é€£æ¥åˆ° Strapi...')
        response = requests.get(f'{STRAPI_URL}/api', headers=headers, verify=False, timeout=30)
        if response.status_code == 200:
            print('âœ… é€£æ¥æˆåŠŸï¼\n')
        else:
            print(f'âŒ é€£æ¥å¤±æ•—: {response.status_code}')
            return
    except Exception as e:
        print(f'âŒ é€£æ¥éŒ¯èª¤: {str(e)}')
        return
    
    # åŒ¯å…¥é é¢
    print('ğŸ“„ é–‹å§‹åŒ¯å…¥é é¢...\n')
    
    page_defs = [
        {'type': 'home', 'file': 'index.html', 'slug': 'index'},
        {'type': 'contact', 'file': 'contact.html', 'slug': 'contact'},
        {'type': 'about', 'file': 'about.html', 'slug': 'about'},
        {'type': 'privacy', 'file': 'privacy.html', 'slug': 'privacy'}
    ]
    
    base_dir = Path(__file__).parent.parent
    success_count = 0
    fail_count = 0
    
    for site_num in range(1, 6):
        site = f'site{site_num}'
        site_dir = base_dir / site
        
        if not site_dir.exists():
            print(f'âš ï¸  æ‰¾ä¸åˆ°ç›®éŒ„ï¼š{site}ï¼Œè·³é')
            continue
        
        print(f'\nè™•ç† {site}...')
        
        for page_def in page_defs:
            file_path = site_dir / page_def['file']
            if not file_path.exists():
                print(f'  â­ï¸  è·³éï¼š{page_def["file"]}ï¼ˆæª”æ¡ˆä¸å­˜åœ¨ï¼‰')
                continue
            
            if import_page(site, page_def['type'], file_path):
                success_count += 1
            else:
                fail_count += 1
    
    print(f'\nğŸ“Š é é¢åŒ¯å…¥å®Œæˆï¼šæˆåŠŸ {success_count}ï¼Œå¤±æ•— {fail_count}')
    print('\nâœ… åŒ¯å…¥å®Œæˆï¼')
    print('\nâš ï¸  æ³¨æ„ï¼š')
    print('   1. å›ºå®šæ–‡ç« å’Œæ¯æ—¥æ–‡ç« éœ€è¦æ‰‹å‹•åŒ¯å…¥')
    print('   2. æˆ–ä½¿ç”¨ Node.js è…³æœ¬ï¼ˆå¦‚æœ SSL å•é¡Œè§£æ±ºï¼‰')

if __name__ == '__main__':
    main()

